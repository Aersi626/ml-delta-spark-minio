version: '3.3'
services:
  python-client:
    build:
      context: ./python-client
      dockerfile: Dockerfile
    container_name: python-client
    environment:
      - SPARK_MASTER=spark://spark:7077
      - SPARK_HOME=/opt/spark-3.3.0-bin-hadoop3
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - MINIO_ENDPOINT=http://minio:9000
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    depends_on:
      - spark
      - minio
      - mlflow
    volumes:
      - ./python-client:/app
    command: ["python", "python-client.py"]
  spark:
    container_name: spark
    image: docker.io/bitnami/spark:3.3
    environment:
      - SPARK_MODE=master
    ports:
      - '8095:8095'
      - '4041:4041'
      - '7074:7074'
    volumes:
      - ./spark_data:/data
  spark-worker:
    container_name: spark-worker
    image: docker.io/bitnami/spark:3.3
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark:7077
      - SPARK_WORKER_MEMORY=4G
      - SPARK_EXECUTOR_MEMORY=4G
      - SPARK_WORKER_CORES=4
    volumes:
      - ./spark_data:/data
  minio:
    container_name: spark-minio 
    image: quay.io/minio/minio
    ports:
      - '9000:9000'
      - '9001:9001'
    volumes:
      - './minio_data:/data'
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
      - MINIO_DEFAULT_BUCKETS=delta-demo
    command: server --console-address ":9001" /data
  
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.9.2
    container_name: mlflow
    environment:
      - AWS_ACCESS_KEY_ID=minioadmin
      - AWS_SECRET_ACCESS_KEY=minioadmin
      - MLFLOW_ARTIFACT_URI=s3://mlflow/
      - MLFLOW_S3_ENDPOINT_URL=http://minio:9000
    command: mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root s3://mlflow/ --host 0.0.0.0 --port 5000
    ports:
      - "5000:5000"
    depends_on:
      - minio
    volumes:
      - ./mlflow:/mlflow